{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742c20bf-70b3-44de-9715-32f709b3b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "from tcpyPI import pi\n",
    "\n",
    "import intake\n",
    "from easygems import healpix as egh\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) # don't warn us about future package conflicts\n",
    "\n",
    "import healpy as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc61c6a-b616-418e-887a-dbc58de145ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING! some models have 3D only when called with different keys!\n",
    "sim_name = \"ifs_tco3999-ng5_deepoff\"\n",
    "out_dir = \"/work/bb1153/b383007/hk25-hamburg/out_data/\"\n",
    "zoom_level = 7\n",
    "time_res=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98984299-9d8a-4c78-9ce8-dfbe07ea7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers=16\n",
    "n_cpu=16\n",
    "memory_limit=\"50GB\"\n",
    "processes=True\n",
    "\n",
    "cluster = LocalCluster(n_workers=n_workers, \n",
    "                       threads_per_worker=n_cpu // n_workers,\n",
    "                       memory_limit=memory_limit,\n",
    "                       processes=processes,\n",
    "                       dashboard_address=46861)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd85260d-654f-4725-8750-1bdb7fd5a329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CERES_EBAF',\n",
       " 'ERA5',\n",
       " 'IR_IMERG',\n",
       " 'JRA3Q',\n",
       " 'MERRA2',\n",
       " 'casesm2_10km_nocumulus',\n",
       " 'icon_d3hp003',\n",
       " 'icon_d3hp003aug',\n",
       " 'icon_d3hp003feb',\n",
       " 'icon_ngc4008',\n",
       " 'ifs_tco2559_rcbmf',\n",
       " 'ifs_tco3999-ng5_deepoff',\n",
       " 'ifs_tco3999-ng5_rcbmf',\n",
       " 'ifs_tco3999-ng5_rcbmf_cf',\n",
       " 'ifs_tco3999_rcbmf',\n",
       " 'nicam_220m_test',\n",
       " 'nicam_gl11',\n",
       " 'scream-dkrz',\n",
       " 'tracking-d3hp003',\n",
       " 'um_Africa_km4p4_RAL3P3_n1280_GAL9_nest',\n",
       " 'um_CTC_km4p4_RAL3P3_n1280_GAL9_nest',\n",
       " 'um_SAmer_km4p4_RAL3P3_n1280_GAL9_nest',\n",
       " 'um_SEA_km4p4_RAL3P3_n1280_GAL9_nest',\n",
       " 'um_glm_n1280_CoMA9_TBv1p2',\n",
       " 'um_glm_n1280_GAL9',\n",
       " 'um_glm_n2560_RAL3p3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_location = \"EU\"\n",
    "cat = intake.open_catalog(\"https://digital-earths-global-hackathon.github.io/catalog/catalog.yaml\")[current_location]\n",
    "list(cat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e21fb6e-3e53-418f-a71b-9c366c94e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"um_\" in sim_name:\n",
    "    ds2d = cat[sim_name](zoom=zoom_level).to_dask()\n",
    "\n",
    "    vnames = {\"sst\":\"ts\", \"psl\":\"psl\", \"t\":\"ta\", \"q\":\"hus\"}\n",
    "\n",
    "    ds3d = cat[sim_name](zoom=zoom_level, time=\"PT3H\").to_dask()\n",
    "    \n",
    "    dim=\"pressure\"\n",
    "    \n",
    "if \"icon_\" in sim_name:\n",
    "    ds2d = cat[sim_name](zoom=zoom_level).to_dask()\n",
    "    \n",
    "    vnames = {\"sst\":\"ts\", \"psl\":\"psl\", \"t\":\"tas\", \"q\":\"huss\"}\n",
    "\n",
    "    ds3d = cat[sim_name](zoom=zoom_level).to_dask()\n",
    "\n",
    "    dim=\"pressure\"\n",
    "    ds3d = ds3d.assign_coords(pressure=ds3d[dim]/100)\n",
    "if \"ifs_\" in sim_name:\n",
    "    ds2d = cat[sim_name](zoom=zoom_level, dim=\"2D\").to_dask()\n",
    "    \n",
    "    vnames = {\"sst\":\"sst\", \"psl\":\"msl\", \"t\":\"t\", \"q\":\"q\"}\n",
    "\n",
    "    ds3d = cat[sim_name](zoom=zoom_level, dim=\"3D\").to_dask()\n",
    "\n",
    "    dim=\"level\"\n",
    "\n",
    "ds3d = ds3d.sortby(dim, ascending=False)\n",
    "time= ds2d.time.where(ds2d.time.dt.hour % time_res == 0, drop=True)\n",
    "\n",
    "ts = ds2d[vnames[\"sst\"]]\n",
    "psl = ds2d[vnames[\"psl\"]]\n",
    "t = ds3d[vnames[\"t\"]]\n",
    "q = ds3d[vnames[\"q\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393da7f5-aa9c-4e38-80a1-c01fff03b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = nside = ds3d.crs.healpix_nside\n",
    "#if (\"icon_\" in sim_name) or (\"um_\" in sim_name):\n",
    "ddeg = 0.2\n",
    "lon = np.arange(0, 360, ddeg)\n",
    "#lat = np.arange(90, -90+ddeg, -ddeg)\n",
    "lat = np.arange(60, -60+ddeg, -ddeg)\n",
    "#else:\n",
    "#    lat = np.sort(ds3d.lat)\n",
    "#    lat = lat[(lat<=60) & (lat>=-60)]\n",
    "#    lon = np.sort(ds3d.lon)\n",
    "pix = xr.DataArray(\n",
    "    hp.ang2pix(nside, *np.meshgrid(lon, lat), nest=True, lonlat=True),\n",
    "    coords=((\"lat\", lat), (\"lon\", lon)),\n",
    "    )\n",
    "\n",
    "#time = ds.time[::time_res]\n",
    "\n",
    "#npix = ds.sizes['cell']\n",
    "\n",
    "# Get pixel indices\n",
    "#pix = np.arange(npix)\n",
    "\n",
    "# Convert pixel indices to angular coordinates\n",
    "#theta, phi = hp.pix2ang(nside, pix, nest=False)  # use nest=True if needed\n",
    "\n",
    "# Convert to latitude and longitude\n",
    "#lat = np.degrees(0.5 * np.pi - theta)  # colatitude to latitude\n",
    "#lon = np.degrees(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1568d353-2af8-480b-a264-cbea12a6aadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1701 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "dimension coordinate 'lat' conflicts between indexed and indexing objects:\n<xarray.DataArray 'lat' (lat: 599, lon: 1800)> Size: 9MB\narray([[ 59.67778523,  60.05627905,  60.05627905, ...,  60.05627905,\n         60.05627905,  60.05627905],\n       [ 59.67778523,  59.67778523,  59.67778523, ...,  59.67778523,\n         59.67778523,  59.67778523],\n       [ 59.29895235,  59.29895235,  59.67778523, ...,  59.67778523,\n         59.67778523,  59.29895235],\n       ...,\n       [-58.91977535, -58.91977535, -59.29895235, ..., -59.29895235,\n        -59.29895235, -58.91977535],\n       [-59.29895235, -59.29895235, -59.29895235, ..., -59.29895235,\n        -59.29895235, -59.29895235],\n       [-59.29895235, -59.29895235, -59.67778523, ..., -59.67778523,\n        -59.67778523, -59.29895235]], shape=(599, 1800))\nCoordinates:\n    lat      (lat, lon) float64 9MB 59.68 60.06 60.06 ... -59.68 -59.68 -59.3\n    lon      (lat, lon) float64 9MB 0.5488 0.5556 0.5556 ... 359.5 359.5 359.5\n    time     datetime64[ns] 8B 2020-01-01\nAttributes:\n    long_name:      latitude\n    units:          degrees_north\n    standard_name:  latitude\nvs.\n<xarray.IndexVariable 'lat' (lat: 599)> Size: 5kB\narray([ 60. ,  59.8,  59.6, ..., -59.2, -59.4, -59.6], shape=(599,))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m lat_chunks = [\u001b[38;5;28mslice\u001b[39m(i, i + chunk_size) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(lat), chunk_size)]\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ti \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(time))):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     ts_ti = \u001b[43mts\u001b[49m\u001b[43m.\u001b[49m\u001b[43msel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m[\u001b[49m\u001b[43mti\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpix\u001b[49m\u001b[43m]\u001b[49m - \u001b[32m273.15\u001b[39m\n\u001b[32m     31\u001b[39m     psl_ti = psl.sel(time=time[ti]).load()[pix] / \u001b[32m100\u001b[39m\n\u001b[32m     32\u001b[39m     t_ti = t.sel(time=time[ti]).load()[:, pix] - \u001b[32m273.15\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/hk25/lib/python3.12/site-packages/xarray/core/dataarray.py:905\u001b[39m, in \u001b[36mDataArray.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_coord(key)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    904\u001b[39m     \u001b[38;5;66;03m# xarray-style array indexing\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43misel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_item_key_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/hk25/lib/python3.12/site-packages/xarray/core/dataarray.py:1539\u001b[39m, in \u001b[36mDataArray.isel\u001b[39m\u001b[34m(self, indexers, drop, missing_dims, **indexers_kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m indexers = either_dict_or_kwargs(indexers, indexers_kwargs, \u001b[33m\"\u001b[39m\u001b[33misel\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_fancy_indexer(idx) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indexers.values()):\n\u001b[32m-> \u001b[39m\u001b[32m1539\u001b[39m     ds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_isel_fancy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1540\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_dims\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1542\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._from_temp_dataset(ds)\n\u001b[32m   1544\u001b[39m \u001b[38;5;66;03m# Much faster algorithm for when all indexers are ints, slices, one-dimensional\u001b[39;00m\n\u001b[32m   1545\u001b[39m \u001b[38;5;66;03m# lists, or zero or one-dimensional np.ndarray's\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/hk25/lib/python3.12/site-packages/xarray/core/dataset.py:2808\u001b[39m, in \u001b[36mDataset._isel_fancy\u001b[39m\u001b[34m(self, indexers, drop, missing_dims)\u001b[39m\n\u001b[32m   2805\u001b[39m selected = \u001b[38;5;28mself\u001b[39m._replace_with_new_dims(variables, coord_names, indexes)\n\u001b[32m   2807\u001b[39m \u001b[38;5;66;03m# Extract coordinates from indexers\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2808\u001b[39m coord_vars, new_indexes = \u001b[43mselected\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexers_coords_and_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2809\u001b[39m variables.update(coord_vars)\n\u001b[32m   2810\u001b[39m indexes.update(new_indexes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/hk25/lib/python3.12/site-packages/xarray/core/dataset.py:2609\u001b[39m, in \u001b[36mDataset._get_indexers_coords_and_indexes\u001b[39m\u001b[34m(self, indexers)\u001b[39m\n\u001b[32m   2605\u001b[39m \u001b[38;5;66;03m# we don't need to call align() explicitly or check indexes for\u001b[39;00m\n\u001b[32m   2606\u001b[39m \u001b[38;5;66;03m# alignment, because merge_variables already checks for exact alignment\u001b[39;00m\n\u001b[32m   2607\u001b[39m \u001b[38;5;66;03m# between dimension coordinates\u001b[39;00m\n\u001b[32m   2608\u001b[39m coords, indexes = merge_coordinates_without_align(coords_list)\n\u001b[32m-> \u001b[39m\u001b[32m2609\u001b[39m \u001b[43massert_coordinate_consistent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2611\u001b[39m \u001b[38;5;66;03m# silently drop the conflicted variables.\u001b[39;00m\n\u001b[32m   2612\u001b[39m attached_coords = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m coords.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._variables}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/hk25/lib/python3.12/site-packages/xarray/core/coordinates.py:1070\u001b[39m, in \u001b[36massert_coordinate_consistent\u001b[39m\u001b[34m(obj, coords)\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m obj.dims:\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# make sure there are no conflict in dimension coordinates\u001b[39;00m\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m coords \u001b[38;5;129;01mand\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m obj.coords \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coords[k].equals(obj[k].variable):\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[32m   1071\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdimension coordinate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m conflicts between \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1072\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mindexed and indexing objects:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mobj[k]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mvs.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcoords[k]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1073\u001b[39m         )\n",
      "\u001b[31mIndexError\u001b[39m: dimension coordinate 'lat' conflicts between indexed and indexing objects:\n<xarray.DataArray 'lat' (lat: 599, lon: 1800)> Size: 9MB\narray([[ 59.67778523,  60.05627905,  60.05627905, ...,  60.05627905,\n         60.05627905,  60.05627905],\n       [ 59.67778523,  59.67778523,  59.67778523, ...,  59.67778523,\n         59.67778523,  59.67778523],\n       [ 59.29895235,  59.29895235,  59.67778523, ...,  59.67778523,\n         59.67778523,  59.29895235],\n       ...,\n       [-58.91977535, -58.91977535, -59.29895235, ..., -59.29895235,\n        -59.29895235, -58.91977535],\n       [-59.29895235, -59.29895235, -59.29895235, ..., -59.29895235,\n        -59.29895235, -59.29895235],\n       [-59.29895235, -59.29895235, -59.67778523, ..., -59.67778523,\n        -59.67778523, -59.29895235]], shape=(599, 1800))\nCoordinates:\n    lat      (lat, lon) float64 9MB 59.68 60.06 60.06 ... -59.68 -59.68 -59.3\n    lon      (lat, lon) float64 9MB 0.5488 0.5556 0.5556 ... 359.5 359.5 359.5\n    time     datetime64[ns] 8B 2020-01-01\nAttributes:\n    long_name:      latitude\n    units:          degrees_north\n    standard_name:  latitude\nvs.\n<xarray.IndexVariable 'lat' (lat: 599)> Size: 5kB\narray([ 60. ,  59.8,  59.6, ..., -59.2, -59.4, -59.6], shape=(599,))"
     ]
    }
   ],
   "source": [
    "p=ds3d[dim]\n",
    "CKCD=0.9\n",
    "\n",
    "def get_pi(ts, psl, p, t, q):\n",
    "    #result = pi(ts, psl, p, t, q, \n",
    "    #            kwargs=dict(CKCD=CKCD, ascent_flag=0, \n",
    "    #                        diss_flag=1, ptop=50, miss_handle=1))\n",
    "    result = xr.apply_ufunc(\n",
    "        pi,\n",
    "        ts, psl, p, t, q,\n",
    "        kwargs=dict(CKCD=CKCD, ascent_flag=0, diss_flag=1, ptop=50, \n",
    "                    miss_handle=1),\n",
    "        input_core_dims=[\n",
    "            [], [], [dim, ], [dim, ], [dim, ],\n",
    "        ],\n",
    "        output_core_dims=[\n",
    "            [], [], [], [], []\n",
    "        ],\n",
    "        vectorize=True\n",
    "    )\n",
    "    vmax, pmin, ifl, t0, otl = result\n",
    "    return vmax, pmin, t0, otl\n",
    "\n",
    "def process_chunk(ts, psl, p, t, q):\n",
    "    return get_pi(ts, psl, p, t, q)\n",
    "\n",
    "chunk_size = 25  # Adjust based on available memory or number of workers\n",
    "lat_chunks = [slice(i, i + chunk_size) for i in range(0, len(lat), chunk_size)]\n",
    "for ti in tqdm(range(len(time))):\n",
    "    ts_ti = ts.sel(time=time[ti]).load()[pix] - 273.15\n",
    "    psl_ti = psl.sel(time=time[ti]).load()[pix] / 100\n",
    "    t_ti = t.sel(time=time[ti]).load()[:, pix] - 273.15\n",
    "    q_ti = q.sel(time=time[ti]).load()[:, pix] * 1000\n",
    "#    if \"icon_\" in sim_name:\n",
    "#        psl_i = psl_i/100\n",
    "    \n",
    "    futures = []\n",
    "    for chunk in lat_chunks:\n",
    "        ts_cti = ts_ti.isel(lat=chunk)\n",
    "        psl_cti = psl_ti.isel(lat=chunk)\n",
    "        t_cti = t_ti.isel(lat=chunk)\n",
    "        q_cti = q_ti.isel(lat=chunk)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore', 'Sending large graph of size', UserWarning)\n",
    "            futures.append(client.submit(process_chunk, ts_cti, psl_cti, p, t_cti, q_cti))\n",
    "        \n",
    "    results = np.array(client.gather(futures), dtype=object)\n",
    "\n",
    "    # Initialize with empty (NaN) arrays for each variable\n",
    "    shape = (1, len(lat), len(lon))\n",
    "    empty_arr = np.full(shape, np.nan, dtype=np.float32)\n",
    "    dims = [\"time\", \"lat\", \"lon\"]\n",
    "    \n",
    "    out_ds = xr.Dataset({\n",
    "            'vmax': (dims, empty_arr.copy()), \n",
    "            'pmin': (dims, empty_arr.copy()),\n",
    "       #     'ifl': (dims, empty_arr),\n",
    "            't0': (dims, empty_arr.copy()),\n",
    "            'otl': (dims, empty_arr.copy()),\n",
    "       #     'sst': (dims, empty_arr),\n",
    "       #     't': (dims, empty_arr),\n",
    "       #     'q': (dims, empty_arr),\n",
    "       #     'msl': (dims, empty_arr),\n",
    "            },\n",
    "            coords={\n",
    "            \"time\": [time[ti].values],\n",
    "            \"lat\": lat,\n",
    "            \"lon\": lon}\n",
    "    )\n",
    "    \n",
    "    # add names and units to the structure\n",
    "    out_ds.vmax.attrs['standard_name'],out_ds.vmax.attrs['units']='Maximum Potential Intensity','m/s'\n",
    "    out_ds.pmin.attrs['standard_name'],out_ds.pmin.attrs['units']='Minimum Central Pressure','hPa'\n",
    "    #out_ds.ifl.attrs['standard_name']='pyPI Flag'\n",
    "    out_ds.t0.attrs['standard_name'],out_ds.t0.attrs['units']='Outflow Temperature','K'\n",
    "    out_ds.otl.attrs['standard_name'],out_ds.otl.attrs['units']='Outflow Temperature Level','hPa'\n",
    "\n",
    "    out_ds[\"vmax\"].loc[dict(time=time[ti])] = xr.concat(results[:,0], dim=\"lat\").values\n",
    "    out_ds[\"pmin\"][0, :, :] = xr.concat(results[:,1], dim=\"lat\").values\n",
    "    out_ds[\"t0\"]  [0, :, :] = xr.concat(results[:,2], dim=\"lat\").values\n",
    "    out_ds[\"otl\"] [0, :, :] = xr.concat(results[:,3], dim=\"lat\").values\n",
    "    #results = [xr.concat(results[i], dim=\"lat\") for i in range(len(out_ds))]\n",
    "    \n",
    "#    out_ds['vmax'][dict(time=time)]  = results[0]\n",
    "#    out_ds['pmin'][dict(time=time)]  = results[1]\n",
    "#    out_ds['ifl'][dict(time=time)]  = results[2]\n",
    "#    out_ds['t0'][dict(time=time)]  = results[3]\n",
    "#    out_ds['otl'][dict(time=time)]  = results[4]\n",
    "\n",
    "    #for key in list(out_ds.keys()):\n",
    "    out_ds.to_netcdf(out_dir+f'{sim_name}_pi_{time[ti].values}'+'.nc')\n",
    "\n",
    "#    vmax, pmin, ifl, t0, otl = result\n",
    "#    out_ds[\"vmax\"][time] = vmax\n",
    "#    out_ds[\"pmin\"][time] = vmax\n",
    "#    out_ds[\"ifl\"][time] = vmax\n",
    "#    out_ds[\"t0\"][time] = vmax\n",
    "#    out_ds[\"otl\"][time] = vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d627e-b75c-4044-8f99-4f8d8ea53e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc798ec7-5bdd-4057-a83f-7de6842b04d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hk25",
   "language": "python",
   "name": "hk25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
